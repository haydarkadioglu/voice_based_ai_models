{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7dfc000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Model\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7decd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'F:\\code\\My GitHub\\voice_based_ai_models\\Models\\research\\audioset\\yamnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75824cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yamnet\n",
    "import params\n",
    "import special_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a539e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = special_params.Params()\n",
    "params.num_classes = 521\n",
    "yamnet_model = yamnet.yamnet_frames_model(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc0d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yamnet_frames\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOp  (1,)                         0         ['input_2[0][0]']             \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_1[0][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.maximum_3 (TFOpLam  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " bda)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLa  ()                           0         ['tf.math.maximum_3[0][0]']   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.cast_2 (TFOpLambda)      ()                           0         ['tf.math.subtract_4[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLam  ()                           0         ['tf.cast_2[0][0]']           \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.ceil_1 (TFOpLambda  ()                           0         ['tf.math.truediv_1[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.cast_3 (TFOpLambda)      ()                           0         ['tf.math.ceil_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLa  ()                           0         ['tf.__operators__.getitem_1[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  ()                           0         ['tf.cast_3[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.maximum_2 (TFOpLam  ()                           0         ['tf.math.subtract_3[0][0]']  \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLa  ()                           0         ['tf.math.multiply_1[0][0]',  \n",
      " mbda)                                                               'tf.math.subtract_4[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  ()                           0         ['tf.math.maximum_2[0][0]',   \n",
      " OpLambda)                                                           'tf.math.subtract_5[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_1 (TFOpLa  (None,)                      0         ['input_2[0][0]',             \n",
      " mbda)                                                               'tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.signal.stft_1 (TFOpLamb  (None, 257)                  0         ['tf.compat.v1.pad_1[0][0]']  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.abs_1 (TFOpLambda)  (None, 257)                  0         ['tf.signal.stft_1[0][0]']    \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_1 (TFOpLa  (None, 64)                   0         ['tf.math.abs_1[0][0]']       \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 64)                   0         ['tf.linalg.matmul_1[0][0]']  \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.log_1 (TFOpLambda)  (None, 64)                   0         ['tf.__operators__.add_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.signal.frame_1 (TFOpLam  (None, 96, 64)               0         ['tf.math.log_1[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 96, 64, 1)            0         ['tf.signal.frame_1[0][0]']   \n",
      "                                                                                                  \n",
      " layer1/conv (Conv2D)        (None, 48, 32, 32)           288       ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " layer1/conv/bn (BatchNorma  (None, 48, 32, 32)           96        ['layer1/conv[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " layer1/relu (ReLU)          (None, 48, 32, 32)           0         ['layer1/conv/bn[0][0]']      \n",
      "                                                                                                  \n",
      " layer2/depthwise_conv (Dep  (None, 48, 32, 32)           288       ['layer1/relu[0][0]']         \n",
      " thwiseConv2D)                                                                                    \n",
      "                                                                                                  \n",
      " layer2/depthwise_conv/bn (  (None, 48, 32, 32)           96        ['layer2/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer2/depthwise_conv/relu  (None, 48, 32, 32)           0         ['layer2/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer2/pointwise_conv (Con  (None, 48, 32, 64)           2048      ['layer2/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer2/pointwise_conv/bn (  (None, 48, 32, 64)           192       ['layer2/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer2/pointwise_conv/relu  (None, 48, 32, 64)           0         ['layer2/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer3/depthwise_conv (Dep  (None, 24, 16, 64)           576       ['layer2/pointwise_conv/relu[0\n",
      " thwiseConv2D)                                                      ][0]']                        \n",
      "                                                                                                  \n",
      " layer3/depthwise_conv/bn (  (None, 24, 16, 64)           192       ['layer3/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer3/depthwise_conv/relu  (None, 24, 16, 64)           0         ['layer3/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer3/pointwise_conv (Con  (None, 24, 16, 128)          8192      ['layer3/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer3/pointwise_conv/bn (  (None, 24, 16, 128)          384       ['layer3/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer3/pointwise_conv/relu  (None, 24, 16, 128)          0         ['layer3/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer4/depthwise_conv (Dep  (None, 24, 16, 128)          1152      ['layer3/pointwise_conv/relu[0\n",
      " thwiseConv2D)                                                      ][0]']                        \n",
      "                                                                                                  \n",
      " layer4/depthwise_conv/bn (  (None, 24, 16, 128)          384       ['layer4/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer4/depthwise_conv/relu  (None, 24, 16, 128)          0         ['layer4/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer4/pointwise_conv (Con  (None, 24, 16, 128)          16384     ['layer4/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer4/pointwise_conv/bn (  (None, 24, 16, 128)          384       ['layer4/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer4/pointwise_conv/relu  (None, 24, 16, 128)          0         ['layer4/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer5/depthwise_conv (Dep  (None, 12, 8, 128)           1152      ['layer4/pointwise_conv/relu[0\n",
      " thwiseConv2D)                                                      ][0]']                        \n",
      "                                                                                                  \n",
      " layer5/depthwise_conv/bn (  (None, 12, 8, 128)           384       ['layer5/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer5/depthwise_conv/relu  (None, 12, 8, 128)           0         ['layer5/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer5/pointwise_conv (Con  (None, 12, 8, 256)           32768     ['layer5/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer5/pointwise_conv/bn (  (None, 12, 8, 256)           768       ['layer5/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer5/pointwise_conv/relu  (None, 12, 8, 256)           0         ['layer5/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer6/depthwise_conv (Dep  (None, 12, 8, 256)           2304      ['layer5/pointwise_conv/relu[0\n",
      " thwiseConv2D)                                                      ][0]']                        \n",
      "                                                                                                  \n",
      " layer6/depthwise_conv/bn (  (None, 12, 8, 256)           768       ['layer6/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer6/depthwise_conv/relu  (None, 12, 8, 256)           0         ['layer6/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer6/pointwise_conv (Con  (None, 12, 8, 256)           65536     ['layer6/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer6/pointwise_conv/bn (  (None, 12, 8, 256)           768       ['layer6/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer6/pointwise_conv/relu  (None, 12, 8, 256)           0         ['layer6/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer7/depthwise_conv (Dep  (None, 6, 4, 256)            2304      ['layer6/pointwise_conv/relu[0\n",
      " thwiseConv2D)                                                      ][0]']                        \n",
      "                                                                                                  \n",
      " layer7/depthwise_conv/bn (  (None, 6, 4, 256)            768       ['layer7/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer7/depthwise_conv/relu  (None, 6, 4, 256)            0         ['layer7/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer7/pointwise_conv (Con  (None, 6, 4, 512)            131072    ['layer7/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer7/pointwise_conv/bn (  (None, 6, 4, 512)            1536      ['layer7/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer7/pointwise_conv/relu  (None, 6, 4, 512)            0         ['layer7/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer8/depthwise_conv (Dep  (None, 6, 4, 512)            4608      ['layer7/pointwise_conv/relu[0\n",
      " thwiseConv2D)                                                      ][0]']                        \n",
      "                                                                                                  \n",
      " layer8/depthwise_conv/bn (  (None, 6, 4, 512)            1536      ['layer8/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer8/depthwise_conv/relu  (None, 6, 4, 512)            0         ['layer8/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer8/pointwise_conv (Con  (None, 6, 4, 512)            262144    ['layer8/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer8/pointwise_conv/bn (  (None, 6, 4, 512)            1536      ['layer8/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer8/pointwise_conv/relu  (None, 6, 4, 512)            0         ['layer8/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer9/depthwise_conv (Dep  (None, 6, 4, 512)            4608      ['layer8/pointwise_conv/relu[0\n",
      " thwiseConv2D)                                                      ][0]']                        \n",
      "                                                                                                  \n",
      " layer9/depthwise_conv/bn (  (None, 6, 4, 512)            1536      ['layer9/depthwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer9/depthwise_conv/relu  (None, 6, 4, 512)            0         ['layer9/depthwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer9/pointwise_conv (Con  (None, 6, 4, 512)            262144    ['layer9/depthwise_conv/relu[0\n",
      " v2D)                                                               ][0]']                        \n",
      "                                                                                                  \n",
      " layer9/pointwise_conv/bn (  (None, 6, 4, 512)            1536      ['layer9/pointwise_conv[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " layer9/pointwise_conv/relu  (None, 6, 4, 512)            0         ['layer9/pointwise_conv/bn[0][\n",
      "  (ReLU)                                                            0]']                          \n",
      "                                                                                                  \n",
      " layer10/depthwise_conv (De  (None, 6, 4, 512)            4608      ['layer9/pointwise_conv/relu[0\n",
      " pthwiseConv2D)                                                     ][0]']                        \n",
      "                                                                                                  \n",
      " layer10/depthwise_conv/bn   (None, 6, 4, 512)            1536      ['layer10/depthwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer10/depthwise_conv/rel  (None, 6, 4, 512)            0         ['layer10/depthwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer10/pointwise_conv (Co  (None, 6, 4, 512)            262144    ['layer10/depthwise_conv/relu[\n",
      " nv2D)                                                              0][0]']                       \n",
      "                                                                                                  \n",
      " layer10/pointwise_conv/bn   (None, 6, 4, 512)            1536      ['layer10/pointwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer10/pointwise_conv/rel  (None, 6, 4, 512)            0         ['layer10/pointwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer11/depthwise_conv (De  (None, 6, 4, 512)            4608      ['layer10/pointwise_conv/relu[\n",
      " pthwiseConv2D)                                                     0][0]']                       \n",
      "                                                                                                  \n",
      " layer11/depthwise_conv/bn   (None, 6, 4, 512)            1536      ['layer11/depthwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer11/depthwise_conv/rel  (None, 6, 4, 512)            0         ['layer11/depthwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer11/pointwise_conv (Co  (None, 6, 4, 512)            262144    ['layer11/depthwise_conv/relu[\n",
      " nv2D)                                                              0][0]']                       \n",
      "                                                                                                  \n",
      " layer11/pointwise_conv/bn   (None, 6, 4, 512)            1536      ['layer11/pointwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer11/pointwise_conv/rel  (None, 6, 4, 512)            0         ['layer11/pointwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer12/depthwise_conv (De  (None, 6, 4, 512)            4608      ['layer11/pointwise_conv/relu[\n",
      " pthwiseConv2D)                                                     0][0]']                       \n",
      "                                                                                                  \n",
      " layer12/depthwise_conv/bn   (None, 6, 4, 512)            1536      ['layer12/depthwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer12/depthwise_conv/rel  (None, 6, 4, 512)            0         ['layer12/depthwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer12/pointwise_conv (Co  (None, 6, 4, 512)            262144    ['layer12/depthwise_conv/relu[\n",
      " nv2D)                                                              0][0]']                       \n",
      "                                                                                                  \n",
      " layer12/pointwise_conv/bn   (None, 6, 4, 512)            1536      ['layer12/pointwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer12/pointwise_conv/rel  (None, 6, 4, 512)            0         ['layer12/pointwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer13/depthwise_conv (De  (None, 3, 2, 512)            4608      ['layer12/pointwise_conv/relu[\n",
      " pthwiseConv2D)                                                     0][0]']                       \n",
      "                                                                                                  \n",
      " layer13/depthwise_conv/bn   (None, 3, 2, 512)            1536      ['layer13/depthwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer13/depthwise_conv/rel  (None, 3, 2, 512)            0         ['layer13/depthwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer13/pointwise_conv (Co  (None, 3, 2, 1024)           524288    ['layer13/depthwise_conv/relu[\n",
      " nv2D)                                                              0][0]']                       \n",
      "                                                                                                  \n",
      " layer13/pointwise_conv/bn   (None, 3, 2, 1024)           3072      ['layer13/pointwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer13/pointwise_conv/rel  (None, 3, 2, 1024)           0         ['layer13/pointwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer14/depthwise_conv (De  (None, 3, 2, 1024)           9216      ['layer13/pointwise_conv/relu[\n",
      " pthwiseConv2D)                                                     0][0]']                       \n",
      "                                                                                                  \n",
      " layer14/depthwise_conv/bn   (None, 3, 2, 1024)           3072      ['layer14/depthwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer14/depthwise_conv/rel  (None, 3, 2, 1024)           0         ['layer14/depthwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " layer14/pointwise_conv (Co  (None, 3, 2, 1024)           1048576   ['layer14/depthwise_conv/relu[\n",
      " nv2D)                                                              0][0]']                       \n",
      "                                                                                                  \n",
      " layer14/pointwise_conv/bn   (None, 3, 2, 1024)           3072      ['layer14/pointwise_conv[0][0]\n",
      " (BatchNormalization)                                               ']                            \n",
      "                                                                                                  \n",
      " layer14/pointwise_conv/rel  (None, 3, 2, 1024)           0         ['layer14/pointwise_conv/bn[0]\n",
      " u (ReLU)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 1024)                 0         ['layer14/pointwise_conv/relu[\n",
      "  (GlobalAveragePooling2D)                                          0][0]']                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 3)                    3075      ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 3)                    0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3220419 (12.28 MB)\n",
      "Trainable params: 3198531 (12.20 MB)\n",
      "Non-trainable params: 21888 (85.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "yamnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13683dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm katmanlar 'yamnet_layers.txt' dosyasına yazıldı.\n"
     ]
    }
   ],
   "source": [
    "# model: örneğin yamnet_model ya da feature_extractor olabilir\n",
    "\n",
    "with open(\"yamnet_layers.txt\", \"w\") as f:\n",
    "    for i, layer in enumerate(yamnet_model.layers):\n",
    "        f.write(f\"{i}: {layer.name} - {layer.__class__.__name__} - {layer.output_shape}\\n\")\n",
    "\n",
    "print(\"Tüm katmanlar 'yamnet_layers.txt' dosyasına yazıldı.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a821d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b19fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a4ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfadd8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessst = yamnet_model(sick_audio_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a0cea96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 521), dtype=float32, numpy=\n",
       " array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 1024), dtype=float32, numpy=\n",
       " array([[5.9133623e-20, 8.0832173e-20, 9.4315715e-21, ..., 4.5528073e-21,\n",
       "         6.8380412e-21, 6.4609543e-21],\n",
       "        [1.9076360e-19, 2.0602628e-19, 1.3075991e-20, ..., 2.0878515e-20,\n",
       "         6.2836081e-21, 1.3356273e-20]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(144, 64), dtype=float32, numpy=\n",
       " array([[-1.048633 , -1.4141245, -2.4498959, ..., -1.7570944, -1.505228 ,\n",
       "         -1.4683931],\n",
       "        [-0.9135425, -1.5830814, -2.2701979, ..., -1.6798733, -1.4297811,\n",
       "         -1.7120833],\n",
       "        [-0.894205 , -1.092468 , -1.5921221, ..., -1.4066528, -1.426339 ,\n",
       "         -1.3806505],\n",
       "        ...,\n",
       "        [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "         -6.9077554],\n",
       "        [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "         -6.9077554],\n",
       "        [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "         -6.9077554]], dtype=float32)>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tessst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e654bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_from_directory(directory_path, num_files=None, max_len=16000):\n",
    "    audio_files = []\n",
    "    for filename in os.listdir(directory_path)[:num_files]:\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            waveform, sr = librosa.load(file_path, sr=16000)\n",
    "\n",
    "            # Uzunluğu sabitle (padding veya truncate)\n",
    "            if len(waveform) < max_len:\n",
    "                waveform = np.pad(waveform, (0, max_len - len(waveform)), mode='constant')\n",
    "            else:\n",
    "                waveform = waveform[:max_len]\n",
    "\n",
    "            audio_files.append(waveform)\n",
    "    return audio_files\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce62c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = 1000\n",
    "\n",
    "sick_audio_files = load_audio_from_directory('../../data/data/Sick', how_many)\n",
    "healthy_audio_files = load_audio_from_directory('../../data/data/Healthy', how_many)\n",
    "none_audio_files = load_audio_from_directory('../../data/data/None', how_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from each class\n",
    "def get_embeddings_from_each_class(num_samples=10):\n",
    "    sick_embeddings = []\n",
    "    healthy_embeddings = []\n",
    "    none_embeddings = []\n",
    "    \n",
    "    # Process samples from each class\n",
    "    for i in range(min(num_samples, len(sick_audio_files))):\n",
    "        _, emb, _ = yamnet_model(sick_audio_files[i])\n",
    "        sick_embeddings.append(tf.reduce_mean(emb, axis=0).numpy())\n",
    "    \n",
    "    for i in range(min(num_samples, len(healthy_audio_files))):\n",
    "        _, emb, _ = yamnet_model(healthy_audio_files[i])\n",
    "        healthy_embeddings.append(tf.reduce_mean(emb, axis=0).numpy())\n",
    "    \n",
    "    for i in range(min(num_samples, len(none_audio_files))):\n",
    "        _, emb, _ = yamnet_model(none_audio_files[i])\n",
    "        none_embeddings.append(tf.reduce_mean(emb, axis=0).numpy())\n",
    "    \n",
    "    # Visualize the embeddings with PCA\n",
    "    from sklearn.decomposition import PCA\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    all_embeddings = np.vstack([sick_embeddings, healthy_embeddings, none_embeddings])\n",
    "    labels = ['Sick'] * len(sick_embeddings) + ['Healthy'] * len(healthy_embeddings) + ['None'] * len(none_embeddings)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(all_embeddings)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, label in enumerate(['Sick', 'Healthy', 'None']):\n",
    "        mask = [l == label for l in labels]\n",
    "        plt.scatter(reduced_embeddings[mask, 0], reduced_embeddings[mask, 1], label=label)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title('YAMNet Embeddings Visualization (PCA)')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.show()\n",
    "    \n",
    "    return sick_embeddings, healthy_embeddings, none_embeddings\n",
    "\n",
    "# Visualize the embeddings\n",
    "sick_embeddings, healthy_embeddings, none_embeddings = get_embeddings_from_each_class(num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b4a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959a275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc7185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703999f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (300, 16000)\n",
      "y shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Etiketler: Sick → 1, Healthy → 0, None → 2\n",
    "X = np.array(sick_audio_files + healthy_audio_files + none_audio_files, dtype=np.float32)\n",
    "y = np.array(\n",
    "    [1] * len(sick_audio_files) + \n",
    "    [0] * len(healthy_audio_files) + \n",
    "    [2] * len(none_audio_files), \n",
    "    dtype=np.int32\n",
    ")\n",
    "\n",
    "print(\"X shape:\", X.shape)  # (örnek_sayısı, örnek_uzunluğu)\n",
    "print(\"y shape:\", y.shape)  # (örnek_sayısı,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Eğitim ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b87001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 16000), (240,), (60, 16000), (60,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5b03608",
   "metadata": {},
   "outputs": [],
   "source": [
    "yamnet_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0658a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1147, in train_step\n        y_pred = self(x, training=True)\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'tf.compat.v1.pad_1' (type TFOpLambda).\n    \n    Shape must be rank 1 but is rank 2 for '{{node yamnet_frames/tf.compat.v1.pad_1/Pad}} = Pad[T=DT_FLOAT, Tpaddings=DT_INT32](IteratorGetNext, yamnet_frames/tf.compat.v1.pad_1/Pad/paddings)' with input shapes: [32,16000], [1,2].\n    \n    Call arguments received by layer 'tf.compat.v1.pad_1' (type TFOpLambda):\n      • tensor=tf.Tensor(shape=(32, 16000), dtype=float32)\n      • paddings=[['0', 'tf.Tensor(shape=(), dtype=int32)']]\n      • mode='CONSTANT'\n      • name=None\n      • constant_values=0.0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43myamnet_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\__autograph_generated_file1o83h0y7.py:15\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     14\u001b[39m     do_return = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(\u001b[38;5;28mself\u001b[39m), ag__.ld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     17\u001b[39m     do_return = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: in user code:\n\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1147, in train_step\n        y_pred = self(x, training=True)\n    File \"f:\\code\\My GitHub\\voice_based_ai_models\\.venv\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'tf.compat.v1.pad_1' (type TFOpLambda).\n    \n    Shape must be rank 1 but is rank 2 for '{{node yamnet_frames/tf.compat.v1.pad_1/Pad}} = Pad[T=DT_FLOAT, Tpaddings=DT_INT32](IteratorGetNext, yamnet_frames/tf.compat.v1.pad_1/Pad/paddings)' with input shapes: [32,16000], [1,2].\n    \n    Call arguments received by layer 'tf.compat.v1.pad_1' (type TFOpLambda):\n      • tensor=tf.Tensor(shape=(32, 16000), dtype=float32)\n      • paddings=[['0', 'tf.Tensor(shape=(), dtype=int32)']]\n      • mode='CONSTANT'\n      • name=None\n      • constant_values=0.0\n"
     ]
    }
   ],
   "source": [
    "yamnet_model.fit(X_train, y_train, epochs=10, batch_size=32, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d44d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f3d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afc144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0279489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444f0531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adece557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5777 - loss: 0.9212\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11089cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Eğer sınıf sayısı 2'den fazlaysa:\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e39769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Doğruluk hesapla\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5ce816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1efc14428d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                              display_labels=['Sick', 'Healthy', 'None'])\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5bb9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        sick       0.48      0.62      0.55       197\n",
      "     healthy       0.82      0.55      0.66       217\n",
      "        none       0.56      0.60      0.58       186\n",
      "\n",
      "    accuracy                           0.59       600\n",
      "   macro avg       0.62      0.59      0.59       600\n",
      "weighted avg       0.63      0.59      0.60       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_names = [\"sick\", \"healthy\", \"none\"]\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
